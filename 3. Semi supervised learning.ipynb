{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from code import nlp\n",
    "from code import utils\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.externals import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "CATEGORIES = [\"Personal info\", \"Internal\", \"Customer info\", \"Public\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be able to apply machine learning on our data we need to vectorize our text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(sublinear_tf=True, max_df=0.5, max_features=8000)\n",
    "clf = BernoulliNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "files_df = pd.read_pickle(\"data/custom_files_labels_done.pkl\")\n",
    "print(files_df.shape)\n",
    "print(files_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "files_df[\"name_transformed\"] = files_df[\"name\"].apply(nlp.stringtofeatures)\n",
    "print(files_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "validation_set = files_df[files_df[\"label\"] != ''].sample(frac=.13, random_state=42)\n",
    "train_set = files_df.drop(validation_set.index)\n",
    "print len(validation_set)\n",
    "print len(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "progress = 10\n",
    "progress_stats = []\n",
    "predicted_stats = []\n",
    "accuracy = []\n",
    "predicted_stats.append(len(train_set[\"label\"][train_set[\"label\"] != '']))\n",
    "progress_stats.append(train_set[\"label\"][train_set[\"label\"] != ''].value_counts())\n",
    "print train_set[\"label\"][train_set[\"label\"] != ''].value_counts()\n",
    "print (\"{} out of {}\").format(len(train_set[\"label\"][train_set[\"label\"] != '']), len(train_set[\"label\"]))\n",
    "\n",
    "vectorizer.fit(train_set[train_set['label'] != '']['name_transformed'].values)\n",
    "clf = BernoulliNB()\n",
    "for row in utils.chunker(train_set[train_set['label'] != ''], 100):\n",
    "    clf.partial_fit(vectorizer.transform(row['name_transformed']), row['label'], CATEGORIES)\n",
    "accuracy.append(clf.score(vectorizer.transform(validation_set[\"name\"]), validation_set[\"label\"]))\n",
    "print accuracy\n",
    "\n",
    "\n",
    "while progress != 0:\n",
    "    vectorizer.fit(train_set[train_set['label'] != '']['name_transformed'].values)\n",
    "    clf = BernoulliNB()\n",
    "    \n",
    "    for row in utils.chunker(train_set[train_set['label'] != ''], 100):\n",
    "            clf.partial_fit(vectorizer.transform(row['name_transformed']), row['label'], CATEGORIES)\n",
    "\n",
    "    predicted_files = 0\n",
    "    non_predicted_files = 0\n",
    "\n",
    "    for index, row in train_set.iterrows():\n",
    "        if row['label'] == '':\n",
    "            vectorized_filename = vectorizer.transform([row['name_transformed']]).toarray()\n",
    "\n",
    "            if np.float64(1) in clf.predict_proba(vectorized_filename):\n",
    "                train_set.loc[index, \"label\"] = clf.predict(vectorized_filename)[0]\n",
    "                predicted_files = predicted_files + 1\n",
    "            else:\n",
    "                non_predicted_files = non_predicted_files + 1\n",
    "    \n",
    "    print(\"Number of predicted files with probability of 1: {}\").format(predicted_files)\n",
    "    vectorizer.fit(train_set[train_set['label'] != '']['name_transformed'].values)\n",
    "    clf = BernoulliNB()\n",
    "    for row in utils.chunker(train_set[train_set['label'] != ''], 100):\n",
    "        clf.partial_fit(vectorizer.transform(row['name_transformed']), row['label'], CATEGORIES)\n",
    "    acc = clf.score(vectorizer.transform(validation_set[\"name\"]), validation_set[\"label\"])\n",
    "    print acc\n",
    "    accuracy.append(acc)\n",
    "    #print files_df[\"label\"][files_df[\"label\"] != ''].value_counts()\n",
    "    progress_stats.append(train_set[\"label\"][train_set[\"label\"] != ''].value_counts())\n",
    "    predicted_stats.append(predicted_files)\n",
    "    progress = predicted_files\n",
    "print \"No more progress\"\n",
    "print train_set[\"label\"][train_set[\"label\"] != ''].value_counts()\n",
    "print (\"{} out of {}\").format(len(train_set[\"label\"][train_set[\"label\"] != '']), len(train_set[\"label\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "progress_frame = pd.DataFrame(data=progress_stats)\n",
    "\n",
    "plt.figure()\n",
    "fig, ax = plt.subplots()\n",
    "#plt.ylabel(\"Number of files added to classifier\")\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.title(\"Logarithmic view of learning rate compared to accuracy\")\n",
    "ax2 = ax.twinx()\n",
    "ax.set_yscale('log')\n",
    "ax.plot(predicted_stats[:], color='#267f8c', linewidth=2., label=\"N files predicted\")\n",
    "ax2.plot(accuracy, color='#abc433', linewidth=2., label=\"Accuracy\")\n",
    "#ax2.set_ylabel(\"Accuracy\")\n",
    "\n",
    "ax.legend(loc=2)\n",
    "ax2.legend()\n",
    "fig.savefig('output/Logarithmic_view_of_learning_rate.png', dpi=1000)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "fig, ax = plt.subplots()\n",
    "plt.title(\"Knowledge in classifier before/after semi supervised learning\")\n",
    "ax2 = ax.twinx()\n",
    "progress_frame.iloc[0].plot(rot=45, color=['#267f8c', '#7db686', '#abc433', '#d3d724'], ylim=[0,1800], position=0.6, kind=\"bar\", width=0.4, ax=ax)\n",
    "progress_frame.iloc[-1].plot(rot=45, color=['#267f8c', '#7db686', '#abc433', '#d3d724'], ylim=[0,1800], position=0.4, kind=\"bar\", width=0.4, ax=ax2)\n",
    "plt.gcf().subplots_adjust(bottom=0.3)\n",
    "fig.savefig('output/Knowledge_in_classifier.png', dpi=1000)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "ax = progress_frame.plot(color=['#267f8c', '#7db686', '#abc433', '#d3d724'], linewidth=2.)\n",
    "ax.xaxis.set_visible(False)\n",
    "plt.title(\"Knowledge gain per category\")\n",
    "plt.ylabel(\"Number of items in classifier\")\n",
    "ax.get_figure().savefig('output/Knowledge_gain_per_category.png', dpi=1000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print non_predicted_files\n",
    "print predicted_files\n",
    "\n",
    "print progress_frame\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "joblib.dump(clf, \"data/joblib/clf_final_iter.pkl\")\n",
    "joblib.dump(vectorizer, \"data/joblib/vectorizer_final_iter.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "files_df.to_pickle(\"data/custom_files_labels_final_iter.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
