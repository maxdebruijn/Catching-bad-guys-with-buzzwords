{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.cluster import KMeans\n",
    "from code import nlp\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bro_logs = pd.read_pickle(\"data/bro_logs_filtered.pkl\")\n",
    "\n",
    "bro_logs_read = bro_logs[bro_logs[\"action\"] == \"SMB::FILE_READ\"]\n",
    "print bro_logs_read.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Prepare classifier and vectorizer and classify all data so further use is easier.\n",
    "\n",
    "clf = joblib.load(\"data/joblib/clf_iter_9.pkl\")\n",
    "vectorizer = joblib.load(\"data/joblib/vectorizer_iter_9.pkl\")\n",
    "\n",
    "def classify_name(filename):\n",
    "    stemmed_filename = [nlp.stringtofeatures(filename)]\n",
    "    vectorized_filename = vectorizer.transform(stemmed_filename)\n",
    "    return clf.predict(vectorized_filename)[0]\n",
    "\n",
    "bro_logs_read[\"classification\"] = bro_logs_read[\"name\"].apply(classify_name)\n",
    "\n",
    "print bro_logs_read.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print bro_logs_read[\"classification\"].unique()\n",
    "\n",
    "def df_to_pretty_avg(df_to_avg):\n",
    "    value_counts = df_to_avg.value_counts(normalize=True)\n",
    "    public = 0.\n",
    "    pii = 0.\n",
    "    cust_info = 0.\n",
    "    internal = 0.\n",
    "    if \"Public\" in value_counts:\n",
    "        public = value_counts[\"Public\"]\n",
    "    if \"Personal info\" in value_counts:\n",
    "        pii = value_counts[\"Personal info\"]\n",
    "    if \"Customer Info\" in value_counts:\n",
    "        cust_info = value_counts[\"Customer Info\"]\n",
    "    if \"Internal\" in value_counts:\n",
    "        internal = value_counts[\"Internal\"]\n",
    "    #print \"pub: {}, emp: {}, cust: {}, int: {}\".format(public, emp_info, cust_info, internal)\n",
    "\n",
    "    return [public, pii, cust_info, internal]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_clusters(data, memory):\n",
    "    cluster_data = []\n",
    "    cluster_labels = []\n",
    "    unique_persons = data[\"id.orig_h\"].unique()\n",
    "\n",
    "    for person in unique_persons:\n",
    "        person_df = data[data[\"id.orig_h\"] == person]\n",
    "        if len(person_df) >= memory:\n",
    "            cluster_data.append(df_to_pretty_avg(person_df[\"classification\"][-memory:]))\n",
    "            cluster_labels.append(person)\n",
    "        \n",
    "    kmeans = KMeans(n_clusters=4)\n",
    "    pred = kmeans.fit_predict(cluster_data)\n",
    "    clusters = {}\n",
    "\n",
    "    for cluster, label in zip(pred, cluster_labels):\n",
    "        if cluster not in clusters.keys():\n",
    "            clusters[cluster] = [label]\n",
    "        else:\n",
    "            clusters[cluster].append(label)\n",
    "        \n",
    "    return clusters\n",
    "\n",
    "print create_clusters(bro_logs_read, 25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Find which arrays belong together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from collections import Counter\n",
    "\n",
    "#http://stackoverflow.com/questions/14720324/compute-the-similarity-between-two-lists\n",
    "#https://en.wikipedia.org/wiki/Cosine_similarity\n",
    "def counter_cosine_similarity(c1, c2):\n",
    "    terms = set(c1).union(c2)\n",
    "    dotprod = sum(c1.get(k, 0) * c2.get(k, 0) for k in terms)\n",
    "    magA = math.sqrt(sum(c1.get(k, 0)**2 for k in terms))\n",
    "    magB = math.sqrt(sum(c2.get(k, 0)**2 for k in terms))\n",
    "    return dotprod / (magA * magB)\n",
    "\n",
    "def length_similarity(c1, c2):\n",
    "    lenc1 = sum(c1.itervalues())\n",
    "    lenc2 = sum(c2.itervalues())\n",
    "    return min(lenc1, lenc2) / float(max(lenc1, lenc2))\n",
    "\n",
    "def similarity_score(l1, l2):\n",
    "    c1, c2 = Counter(l1), Counter(l2)\n",
    "    return length_similarity(c1, c2) * counter_cosine_similarity(c1, c2)  \n",
    "\n",
    "def similar_match(c1, c2):\n",
    "    similar_match_dict = {}\n",
    "    for old_key, old_value in c1.iteritems():\n",
    "        for new_key, new_value in c2.iteritems():\n",
    "            similarity = counter_cosine_similarity(Counter(old_value), Counter(new_value))\n",
    "            if old_key not in similar_match_dict.keys():\n",
    "                similar_match_dict[old_key] = {'new_key':new_key, 'similarity': similarity}\n",
    "            else:\n",
    "                if similarity > similar_match_dict[old_key][\"similarity\"]:\n",
    "                    similar_match_dict[old_key][\"new_key\"] = new_key\n",
    "                    similar_match_dict[old_key][\"similarity\"] = similarity\n",
    "\n",
    "    return similar_match_dict\n",
    "old_cluster = create_clusters(bro_logs_read, 25)\n",
    "new_cluster = create_clusters(bro_logs_read, 30)\n",
    "match = similar_match(old_cluster, new_cluster)\n",
    "print match"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Find which values were added to a different cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def notify_change(match, previous_cluster, new_cluster):\n",
    "    for k, v in match.iteritems():\n",
    "        #print v\n",
    "        for new_item in new_cluster[v[\"new_key\"]]:\n",
    "            if new_item not in previous_cluster[k]:\n",
    "                print(\"{} changed clusters\").format(new_item)\n",
    "\n",
    "                \n",
    "notify_change(match, old_cluster, new_cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we see how the algorithm behaves let's simulate it running in a live environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "previous_cluster = {}\n",
    "for i in range(len(bro_logs_read)):\n",
    "    new_cluster = create_clusters(bro_logs_read[:i+5000], 25)\n",
    "    match = similar_match(previous_cluster, new_cluster)\n",
    "    notify_change(match, previous_cluster, new_cluster)\n",
    "    previous_cluster = new_cluster\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
